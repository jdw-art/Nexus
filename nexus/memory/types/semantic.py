"""è¯­ä¹‰è®°å¿†å®ç°

ç»“åˆå‘é‡æ£€ç´¢å’ŒçŸ¥è¯†å›¾è°±çš„æ··åˆè¯­ä¹‰è®°å¿†ï¼Œä½¿ç”¨ï¼š
- HuggingFace ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ–‡æœ¬åµŒå…¥
- å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢è¿›è¡Œå¿«é€Ÿåˆç­›
- çŸ¥è¯†å›¾è°±è¿›è¡Œå®ä½“å…³ç³»æ¨ç†
- æ··åˆæ£€ç´¢ç­–ç•¥ä¼˜åŒ–ç»“æœè´¨é‡
"""

from typing import List, Dict, Any, Optional, Set, Tuple
from datetime import datetime, timedelta
import json
import logging
import math
import numpy as np

from ..base import BaseMemory, MemoryItem, MemoryConfig
from ..embedding import get_text_embedder, get_dimension


# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class Entity:
    """å®ä½“ç±»"""
    def __init__(
            self,
            entity_id: int,
            name: str,
            entity_type: str,
            description: str,
            properties: Dict[str, Any] = None
    ):
        self.entity_id = entity_id
        self.name = name
        self.entity_type = entity_type  # PERSON, ORG, PRODUCT, SKILL, CONCEPTç­‰
        self.description = description
        self.properties = properties or {}
        self.created_at = datetime.now()
        self.updated_at = datetime.now()
        self.frequency = 1      # å‡ºç°é¢‘ç‡

    def to_dict(self) -> Dict[str, Any]:
        return {
            "entity_id": self.entity_id,
            "name": self.name,
            "entity_type": self.entity_type,
            "description": self.description,
            "properties": self.properties,
            "frequency": self.frequency
        }

class Relation:
    """å…³ç³»ç±»"""
    def __init__(
            self,
            from_entity: str,
            to_entity: str,
            relation_type: str,
            strength: float = 1.0,
            evidence: str = "",
            properties: Dict[str, Any] = None
    ):
        self.from_entity = from_entity
        self.to_entity = to_entity
        self.relation_type = relation_type
        self.strength = strength
        self.evidence = evidence    # æ”¯æŒè¯¥å…³ç³»çš„åŸæ–‡æœ¬
        self.properties = properties or {}
        self.created_at = datetime.now()
        self.frequency = 1  # å…³ç³»å‡ºç°é¢‘ç‡

    def to_dict(self) -> Dict[str, Any]:
        return {
            "from_entity": self.from_entity,
            "to_entity": self.to_entity,
            "relation_type": self.relation_type,
            "strength": self.strength,
            "evidence": self.evidence,
            "properties": self.properties,
            "frequency": self.frequency
        }

class SemanticMemory(BaseMemory):
    """
    å¢å¼ºè¯­ä¹‰è®°å¿†å®ç°

    ç‰¹ç‚¹ï¼š
    - ä½¿ç”¨HuggingFaceä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ–‡æœ¬åµŒå…¥
    - å‘é‡æ£€ç´¢è¿›è¡Œå¿«é€Ÿç›¸ä¼¼åº¦åŒ¹é…
    - çŸ¥è¯†å›¾è°±å­˜å‚¨å®ä½“å’Œå…³ç³»
    - æ··åˆæ£€ç´¢ç­–ç•¥ï¼šå‘é‡+å›¾+è¯­ä¹‰æ¨ç†
    """
    def __init__(self, config: MemoryConfig, storage_backend=None):
        super().__init__(config, storage_backend)

        # åµŒå…¥æ¨¡å‹ï¼ˆç»Ÿä¸€æä¾›ï¼‰
        self.embedding_model = None
        self._init_embedding_model()

        # ä¸“ä¸šæ•°æ®åº“å­˜å‚¨
        self.vector_store = None
        self.graph_store = None
        self._init_databases()

        # å®ä½“å’Œå…³ç³»å­˜å‚¨ï¼ˆç”¨äºå¿«é€Ÿè®¿é—®ï¼‰
        self.entities: Dict[str, Entity] = {}
        self.relations: List[Relation] = []

        # å®ä½“è¯†åˆ«å™¨
        self.nlp = None
        self._init_nlp()

        # è®°å¿†å­˜å‚¨
        self.semantic_memories: List[MemoryItem] = []
        self.memory_embeddings: Dict[str, np.ndarray] = {}

        logger.info("å¢å¼ºè¯­ä¹‰è®°å¿†åˆå§‹åŒ–å®Œæˆï¼ˆä½¿ç”¨Qdrant+Neo4jä¸“ä¸šæ•°æ®åº“ï¼‰")


    def _init_embedding_model(self):
        """åˆå§‹åŒ–ç»Ÿä¸€åµŒå…¥æ¨¡å‹ï¼ˆç”± embedding_provider ç®¡ç†ï¼‰ã€‚"""
        try:
            self.embedding_model = get_text_embedder()
            # è½»é‡å¥åº·æ£€æŸ¥ä¸æ—¥å¿—
            try:
                test_vec = self.embedding_model.encode("health_check")
                dim = getattr(self.embedding_model, "dimension", len(test_vec))
                logger.info(f"âœ… åµŒå…¥æ¨¡å‹å°±ç»ªï¼Œç»´åº¦: {dim}")
            except Exception:
                logger.info("âœ… åµŒå…¥æ¨¡å‹å°±ç»ª")
        except Exception as e:
            logger.error(f"âŒ åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def _init_databases(self):
        """åˆå§‹åŒ–ä¸“ä¸šæ•°æ®åº“å­˜å‚¨"""
        try:
            from ...core.database_config import get_database_config
            # è·å–æ•°æ®åº“é…ç½®
            db_config = get_database_config()

            # åˆå§‹åŒ–Qdrantå‘é‡æ•°æ®åº“ï¼ˆä½¿ç”¨è¿æ¥ç®¡ç†å™¨é¿å…é‡å¤è¿æ¥ï¼‰
            from ..storage.qdrant_store import QdrantConnectionManager
            qdrant_config = db_config.get_qdrant_config() or {}
            qdrant_config["vector_size"] = get_dimension()
            self.vector_store = QdrantConnectionManager.get_instance(**qdrant_config)
            logger.info("âœ… Qdrantå‘é‡æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

            # åˆå§‹åŒ–Neo4jå›¾æ•°æ®åº“
            from ..storage.neo4j_store import Neo4jGraphStore
            neo4j_config = db_config.get_neo4j_config()
            self.graph_store = Neo4jGraphStore(**neo4j_config)
            logger.info("âœ… Neo4jå›¾æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

            # éªŒè¯è¿æ¥
            vector_health = self.vector_store.health_check()
            graph_health = self.graph_store.health_check()

            if not vector_health:
                logger.warning("âš ï¸ Qdrantè¿æ¥å¼‚å¸¸ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™")
            if not graph_health:
                logger.warning("âš ï¸ Neo4jè¿æ¥å¼‚å¸¸ï¼Œå›¾æœç´¢åŠŸèƒ½å¯èƒ½å—é™")

            logger.info(
                f"ğŸ¥ æ•°æ®åº“å¥åº·çŠ¶æ€: Qdrant={'âœ…' if vector_health else 'âŒ'}, Neo4j={'âœ…' if graph_health else 'âŒ'}")

        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.info("ğŸ’¡ è¯·æ£€æŸ¥æ•°æ®åº“é…ç½®å’Œç½‘ç»œè¿æ¥")
            logger.info("ğŸ’¡ å‚è€ƒ DATABASE_SETUP_GUIDE.md è¿›è¡Œé…ç½®")
            raise

    def _init_nlp(self):
        """åˆå§‹åŒ–NLPå¤„ç†å™¨ - æ™ºèƒ½å¤šè¯­è¨€æ”¯æŒ"""
        try:
            import spacy
            self.nlp_models = {}

            # å°è¯•åŠ è½½å¤šè¯­è¨€æ¨¡å‹
            models_to_try = [
                ("zh_core_web_sm", "ä¸­æ–‡"),
                ("en_core_web_sm", "è‹±æ–‡")
            ]

            loaded_models = []
            for model_name, lang_name in models_to_try:
                try:
                    nlp = spacy.load(model_name)
                    self.nlp_models[model_name] = nlp
                    loaded_models.append(lang_name)
                    logger.info(f"âœ… åŠ è½½{lang_name}spaCyæ¨¡å‹: {model_name}")
                except OSError:
                    logger.warning(f"âš ï¸ {lang_name}spaCyæ¨¡å‹ä¸å¯ç”¨: {model_name}")

            # è®¾ç½®ä¸»è¦NLPå¤„ç†å™¨
            if "zh_core_web_sm" in self.nlp_models:
                self.nlp = self.nlp_models["zh_core_web_sm"]
                logger.info("ğŸ¯ ä¸»è¦ä½¿ç”¨ä¸­æ–‡spaCyæ¨¡å‹")
            elif "en_core_web_sm" in self.nlp_models:
                self.nlp = self.nlp_models["en_core_web_sm"]
                logger.info("ğŸ¯ ä¸»è¦ä½¿ç”¨è‹±æ–‡spaCyæ¨¡å‹")
            else:
                self.nlp = None
                logger.warning("âš ï¸ æ— å¯ç”¨spaCyæ¨¡å‹ï¼Œå®ä½“æå–å°†å—é™")

            if loaded_models:
                logger.info(f"ğŸ“š å¯ç”¨è¯­è¨€æ¨¡å‹: {', '.join(loaded_models)}")

        except ImportError:
            logger.warning("âš ï¸ spaCyä¸å¯ç”¨ï¼Œå®ä½“æå–å°†å—é™")
            self.nlp = None
            self.nlp_models = {}

    def add(self, memory_item: MemoryItem) -> str:
        """æ·»åŠ è¯­ä¹‰è®°å¿†"""
        try:
            # 1. ç”Ÿæˆæ–‡æœ¬åµŒå…¥
            embedding = self.embedding_model.encode(memory_item.content)
            self.memory_embeddings[memory_item.id] = embedding

            # todo: 2. æå–å®ä½“å’Œå…³ç³»

            # 3. å­˜å‚¨åˆ°Neo4jæ•°æ®åº“

            # 4. å­˜å‚¨åˆ°Qdrantæ•°æ®åº“
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ è¯­ä¹‰è®°å¿†å¤±è´¥: {e}")
            raise
