"""Reflection Agentå®ç° - è‡ªæˆ‘åæ€ä¸è¿­ä»£ä¼˜åŒ–çš„æ™ºèƒ½ä½“"""
from typing import List, Dict, Any, Optional

from langgraph.func import task

from ..core.agent import Agent
from ..core.llm import NexusLLM
from ..core.config import Config
from ..core.message import Message
from ..tools.registry import ToolRegistry

DEFAULT_PROMPT = {
    "initial": """
è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚å®Œæˆä»»åŠ¡ï¼š

ä»»åŠ¡: {task}

è¯·æä¾›ä¸€ä¸ªå®Œæ•´ã€å‡†ç¡®çš„å›ç­”ã€‚
""",
    "reflect": """
è¯·ä»”ç»†å®¡æŸ¥ä»¥ä¸‹å›ç­”ï¼Œå¹¶æ‰¾å‡ºå¯èƒ½çš„é—®é¢˜æˆ–æ”¹è¿›ç©ºé—´ï¼š

# åŸå§‹ä»»åŠ¡:
{task}

# å½“å‰å›ç­”:
{content}

è¯·åˆ†æè¿™ä¸ªå›ç­”çš„è´¨é‡ï¼ŒæŒ‡å‡ºä¸è¶³ä¹‹å¤„ï¼Œå¹¶æå‡ºå…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚
å¦‚æœå›ç­”å·²ç»å¾ˆå¥½ï¼Œè¯·å›ç­”"æ— éœ€æ”¹è¿›"ã€‚
""",
    "refine": """
è¯·æ ¹æ®åé¦ˆæ„è§æ”¹è¿›ä½ çš„å›ç­”ï¼š

# åŸå§‹ä»»åŠ¡:
{task}

# ä¸Šä¸€è½®å›ç­”:
{last_attempt}

# åé¦ˆæ„è§:
{feedback}

è¯·æä¾›ä¸€ä¸ªæ”¹è¿›åçš„å›ç­”ã€‚
"""
}

class Memory:
    """ç®€å•çš„çŸ­æœŸè®°å¿†æ¨¡å—ï¼Œç”¨äºå­˜å‚¨æ™ºèƒ½ä½“çš„è¡ŒåŠ¨ä¸åæ€è½¨è¿¹"""
    def __init__(self):
        self.records: List[Dict[str, Any]] = []

    def add_record(self, record_type: str, content: str):
        """å‘è®°å¿†ä¸­æ·»åŠ ä¸€æ¡è®°å½•"""
        self.records.append({"type": record_type, "content": content})
        print(f"ğŸ“ è®°å¿†å·²æ›´æ–°ï¼Œæ–°å¢ä¸€æ¡ '{record_type}' è®°å½•ã€‚")

    def get_trajectory(self) -> str:
        """å°†æ‰€æœ‰è®°å¿†è®°å½•æ ¼å¼åŒ–ä¸ºä¸€ä¸²è¿è´¯çš„å­—ç¬¦ä¸²æ–‡æœ¬"""
        trajectory = ""
        for record in self.records:
            if record["type"] == "execution":
                trajectory += f"--- ä¸Šä¸€è½®å°è¯• (ä»£ç ) ---\n{record['content']}\n\n"
            elif record['type'] == 'reflection':
                trajectory += f"--- è¯„å®¡å‘˜åé¦ˆ ---\n{record['content']}\n\n"
        return trajectory.strip()

    def get_last_execution(self) -> str:
        """è·å–æœ€è¿‘ä¸€æ¬¡çš„æ‰§è¡Œç»“æœ"""
        for record in reversed(self.records):
            if record["type"] == "execution":
                return record["content"]
        return ""

class ReflectionAgent(Agent):
    """
    Reflection Agent - è‡ªæˆ‘åæ€ä¸è¿­ä»£ä¼˜åŒ–çš„æ™ºèƒ½ä½“

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æ‰§è¡Œåˆå§‹ä»»åŠ¡
    2. å¯¹ç»“æœè¿›è¡Œè‡ªæˆ‘åæ€
    3. æ ¹æ®åæ€ç»“æœè¿›è¡Œä¼˜åŒ–
    4. è¿­ä»£æ”¹è¿›ç›´åˆ°æ»¡æ„

    ç‰¹åˆ«é€‚åˆä»£ç ç”Ÿæˆã€æ–‡æ¡£å†™ä½œã€åˆ†ææŠ¥å‘Šç­‰éœ€è¦è¿­ä»£ä¼˜åŒ–çš„ä»»åŠ¡ã€‚

    æ”¯æŒå¤šç§ä¸“ä¸šé¢†åŸŸçš„æç¤ºè¯æ¨¡æ¿ï¼Œç”¨æˆ·å¯ä»¥è‡ªå®šä¹‰æˆ–ä½¿ç”¨å†…ç½®æ¨¡æ¿ã€‚
    """
    def __init__(
            self,
            name: str,
            llm: NexusLLM,
            system_prompt: Optional[str] = None,
            config: Optional[Config] = None,
            max_iterations: int = 3,
            custom_prompt: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–ReflectionAgent
        :param name: Agentåç§°
        :param llm: LLMå®ä¾‹
        :param system_prompt: ç³»ç»Ÿæç¤ºè¯
        :param config: é…ç½®å¯¹è±¡
        :param max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        :param custom_prompt: è‡ªå®šä¹‰æç¤ºè¯æ¨¡ç‰ˆ  {"initial": "", "reflect": "", "refine": ""}
        """
        super().__init__(name, llm, system_prompt, config)
        self.max_iterations = max_iterations
        self.memory = Memory()

        # è®¾ç½®æç¤ºè¯æ¨¡ç‰ˆï¼Œç”¨æˆ·è‡ªå®šä¹‰ä¼˜å…ˆï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤æ¨¡ç‰ˆ
        self.prompts = custom_prompt if custom_prompt else DEFAULT_PROMPT

    def run(self, input_text: str, **kwargs) -> str:
        """
        è¿è¡Œ Reflection Agent
        :param input_text: ç”¨æˆ·è¾“å…¥
        :param kwargs: å…¶ä»–å‚æ•°
        :return: æœ€ç»ˆä¼˜åŒ–åçš„ç»“æœ
        """
        print(f"\nğŸ¤– {self.name} å¼€å§‹å¤„ç†ä»»åŠ¡: {input_text}")

        # é‡ç½®è®°å¿†
        self.memory = Memory()

        # 1. åˆå§‹æ‰§è¡Œ
        print("\n--- æ­£åœ¨è¿›è¡Œåˆå§‹å°è¯• ---")
        initial_prompt = self.prompts["initial"].format(task=input_text)
        initial_result = self._get_llm_response(initial_prompt, **kwargs)
        self.memory.add_record("execution", initial_result)

        # 2. è¿­ä»£å¾ªç¯ï¼šåæ€ä¸ä¼˜åŒ–
        for i in range(self.max_iterations):
            print(f"\n--- ç¬¬ {i + 1}/{self.max_iterations} è½®è¿­ä»£ ---")

            # 2.1 åæ€
            print("\n-> æ­£åœ¨è¿›è¡Œåæ€...")
            last_result = self.memory.get_last_execution()
            reflect_prompt = self.prompts["reflect"].format(
                content=last_result,
                task=input_text
            )
            feedback = self._get_llm_response(reflect_prompt, **kwargs)
            self.memory.add_record("reflection", feedback)

            # 2.2 æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
            if "æ— éœ€æ”¹è¿›" in feedback or "no need for improvement" in feedback.lower():
                print("\nâœ… åæ€è®¤ä¸ºç»“æœå·²æ— éœ€æ”¹è¿›ï¼Œä»»åŠ¡å®Œæˆã€‚")
                break

            # 2.3 ä¼˜åŒ–
            print("\n-> æ­£åœ¨è¿›è¡Œä¼˜åŒ–...")
            refine_prompt = self.prompts["refine"].format(
                task=input_text,
                last_attempt=last_result,
                feedback=feedback
            )
            refined_result = self._get_llm_response(refine_prompt, **kwargs)
            self.memory.add_record("execution", refined_result)

        final_result = self.memory.get_last_execution()
        print(f"\n--- ä»»åŠ¡å®Œæˆ ---\næœ€ç»ˆç»“æœ:\n{final_result}")

        # ä¿å­˜åˆ°å†å²è®°å½•
        self.add_message(Message(input_text, "user"))
        self.add_message(Message(final_result, "assistant"))

        return final_result

    def _get_llm_response(self, prompt: str, **kwargs) -> str:
        """è°ƒç”¨LLMå¹¶è·å–å®Œæ•´å“åº”"""
        messages = [{"role": "user", "content": prompt}]
        return self.llm.invoke(messages, **kwargs) or ""